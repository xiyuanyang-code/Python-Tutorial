{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d07f3f0",
   "metadata": {},
   "source": [
    "# Tutorial for Scraping(1): Beautiful Soup for parsing HTML file\n",
    "\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n",
    "\n",
    "- XML (Extensible Markup Language)\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<bookstore>\n",
    "  <book category=\"cooking\">\n",
    "    <title lang=\"en\">Everyday Italian</title>\n",
    "    <author>Giada De Laurentiis</author>\n",
    "    <year>2005</year>\n",
    "    <price>30.00</price>\n",
    "  </book>\n",
    "  <book category=\"children\">\n",
    "    <title lang=\"en\">Harry Potter</title>\n",
    "    <author>J.K. Rowling</author>\n",
    "    <year>2005</year>\n",
    "    <price>29.99</price>\n",
    "  </book>\n",
    "</bookstore>\n",
    "```\n",
    "\n",
    "- HTML (HyperText Markup Language)\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "  <title>我的书店</title>\n",
    "  <style>\n",
    "    body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "    h1 { color: #333; }\n",
    "    .book { border: 1px solid #ccc; padding: 15px; margin-bottom: 10px; }\n",
    "    .book strong { color: #007bff; }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "  <h1>我的书店</h1>\n",
    "\n",
    "  <div class=\"book\">\n",
    "    <h2>书名：Everyday Italian (英文)</h2>\n",
    "    <p><strong>作者：</strong> Giada De Laurentiis</p>\n",
    "    <p><strong>出版年份：</strong> 2005</p>\n",
    "    <p><strong>价格：</strong> $30.00</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"book\">\n",
    "    <h2>书名：Harry Potter (英文)</h2>\n",
    "    <p><strong>作者：</strong> J.K. Rowling</p>\n",
    "    <p><strong>出版年份：</strong> 2005</p>\n",
    "    <p><strong>价格：</strong> $29.99</p>\n",
    "  </div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e10cb",
   "metadata": {},
   "source": [
    "## Quick Setup\n",
    "\n",
    "Before using `bs4` to scrap, let us start up quickly to parse an HTML file locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./demo.html\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    html_content: str = file.read()\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d15c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# accept an html string and parse it\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "print(soup.prettify())\n",
    "# Prints the values to a stream, or to sys.stdout by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4e478",
   "metadata": {},
   "source": [
    "Then, you can almost do whatever you can do in `JavaScripts`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The tile is {soup.title}\")\n",
    "# The tile is <title>The Dormouse's story</title>\n",
    "\n",
    "# to make it prettier\n",
    "print(f\"The tile is {soup.title.get_text()}\")\n",
    "\n",
    "# equivalent to this:\n",
    "print(soup.find(\"title\"))\n",
    "print(soup.find(\"title\").get_text())\n",
    "\n",
    "# find all content\n",
    "result = list(soup.find_all(\"p\"))\n",
    "print(len(result))\n",
    "print(result[1].get_text())\n",
    "\n",
    "# get all the text\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f95662",
   "metadata": {},
   "source": [
    "## Parser\n",
    "\n",
    "| Parser          | Typical usage                          | Advantages                                                                   | Disadvantages                                     |\n",
    "| :-------------- | :------------------------------------- | :--------------------------------------------------------------------------- | :------------------------------------------------ |\n",
    "| Python's html.parser | `BeautifulSoup(markup, \"html.parser\")` | - Batteries included <br> - Decent speed                                       | - Not as fast as lxml, less lenient than html5lib. |\n",
    "| lxml's HTML parser | `BeautifulSoup(markup, \"lxml\")`        | - Very fast                                                                  | - External C dependency                           |\n",
    "| lxml's XML parser  | `BeautifulSoup(markup, \"lxml-xml\")` <br> `BeautifulSoup(markup, \"xml\")` | - Very fast <br> - The only currently supported XML parser                     | - External C dependency                           |\n",
    "| html5lib        | `BeautifulSoup(markup, \"html5lib\")`    | - Extremely lenient <br> - Parses pages the same way a web browser does <br> - Creates valid HTML5 | - Very slow <br> - External Python dependency     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da49d7",
   "metadata": {},
   "source": [
    "## Kind of Objects\n",
    "\n",
    "### `tag`\n",
    "\n",
    "- `tag`: The same in JavaScripts. A Tag object corresponds to an XML or HTML tag in the original document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953045f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    soup_2 = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "tag = soup_2.find(\"p\")\n",
    "\n",
    "# several info messages for this tag\n",
    "print(tag)\n",
    "print(type(tag))\n",
    "print(tag.name)\n",
    "\n",
    "# attrs\n",
    "# it will return a dict\n",
    "print(tag.attrs)\n",
    "print(tag.attrs.keys())\n",
    "\n",
    "# when not found, this will throw an error\n",
    "print(tag[\"id\"])\n",
    "print(tag[\"class\"])\n",
    "\n",
    "# you can change the settings of the tag!\n",
    "tag.name = \"changed_tag_name\"\n",
    "print(tag)\n",
    "\n",
    "# changing the attrs\n",
    "tag['id'] = 'verybold'\n",
    "tag['another-attribute'] = 1\n",
    "print(tag.attrs)\n",
    "print(soup_2.prettify())\n",
    "\n",
    "# print(soup_2)\n",
    "# # write back to the original file\n",
    "# with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "#     # write the new str\n",
    "#     file.write(soup_2.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055be5b3",
   "metadata": {},
   "source": [
    "### class NavigableString\n",
    "\n",
    "A tag can contain strings as pieces of text. Beautiful Soup uses the `NavigableString` class to contain these pieces of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_3 = BeautifulSoup(\"<p>Welcome<b>Hello</b>text</p>\", \"html.parser\")\n",
    "\n",
    "tag_3 = soup_3.find(\"b\")\n",
    "print(tag_3.string)\n",
    "\n",
    "tag_3.string.replace_with(\"test\")\n",
    "\n",
    "print(tag_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d27a6",
   "metadata": {},
   "source": [
    "### Navigating the DOM Tree\n",
    "\n",
    "- `.children`: return a generator for all the child of this element.\n",
    "\n",
    "- `.descendants`: iterate over all of a tag's children, recursively: its direct children, the children of its direct children. \n",
    "\n",
    "- `.string` and `.content`:\n",
    "    - If a tag has only one child, and that child is a NavigableString, the child is made available as `.string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde17a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "\n",
    "# open the html file\n",
    "with open(\"./demo2.html\", \"r\") as file:\n",
    "    soup_new = BeautifulSoup(file, \"lxml\")\n",
    "\n",
    "# find all the children\n",
    "\n",
    "tag_installation = soup_new.find(id=\"installation-section\")\n",
    "print(tag_installation)\n",
    "\n",
    "# for child in tag_installation.children:\n",
    "#     print(child)\n",
    "\n",
    "# it is a generator!\n",
    "# print(type(tag_installation.children))\n",
    "\n",
    "# you can transform that into a list\n",
    "child_list = list(tag_installation.children)\n",
    "print(len(child_list))\n",
    "print(r\"Numbers of \\n: \", child_list.count(\"\\n\")) \n",
    "\n",
    "# if you want to ignore '\\n':\n",
    "filtered_string = [child for child in tag_installation.children if not (isinstance(child, NavigableString) and child.strip() == \"\")]\n",
    "print(len(filtered_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag_installation.string)\n",
    "\n",
    "# split into array, the same as list(tag_installation.children)\n",
    "print(tag_installation.contents)\n",
    "\n",
    "filtered = list(filter(lambda x: x != \"\\n\", tag_installation.contents))\n",
    "print(filtered)\n",
    "\n",
    "for content in filtered:\n",
    "    print(content.string)\n",
    "\n",
    "\n",
    "# or you can use the descendants methods\n",
    "all_des = list(filter(lambda x: x != \"\\n\", tag_installation.descendants))\n",
    "print(all_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e32854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in all_des:\n",
    "    print(content)\n",
    "    print(content.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f9b47",
   "metadata": {},
   "source": [
    "# Using `requests` to see a website's HTML\n",
    "\n",
    "The key to scrapping files is **understanding files' structure**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b69b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://baidu.com\")\n",
    "response.encoding = \"utf-8\"\n",
    "\n",
    "get_text = response.text\n",
    "soup_baidu = BeautifulSoup(get_text)\n",
    "\n",
    "print(soup_baidu.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80f63e",
   "metadata": {},
   "source": [
    "## A Small Demo\n",
    "\n",
    "We will trying to get some information about my own github channel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6784d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://github.com/xiyuanyang-code\"\n",
    "response = requests.get(URL)\n",
    "response.encoding = \"utf-8\"\n",
    "\n",
    "# print(BeautifulSoup(response.text).prettify())\n",
    "\n",
    "soup_github = BeautifulSoup(response.text)\n",
    "print(soup_github.title)\n",
    "print(soup_github.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc301a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = list(filter(lambda x: x != \"\\n\", soup_github))\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30412ac",
   "metadata": {},
   "source": [
    "Let's see another demo? How will you paste content on a web? Maybe you can use your mouse to scroll down or press `Ctrl + A` command and copy it. Now you can use scrapping to finish this!\n",
    "\n",
    "We will use Lilian Weng's Blog [How we think](https://lilianweng.github.io/posts/2025-05-01-thinking/) as a demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c94c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_2 = \"https://lilianweng.github.io/posts/2025-05-01-thinking/\"\n",
    "response = requests.get(\"https://lilianweng.github.io/posts/2025-05-01-thinking/\")\n",
    "response.encoding = \"utf-8\"\n",
    "\n",
    "# print(BeautifulSoup(response.text).prettify())\n",
    "\n",
    "soup_lilian = BeautifulSoup(response.text)\n",
    "print(soup_lilian.find(\"title\").get_text())\n",
    "paras = soup_lilian.find_all(\"p\")\n",
    "\n",
    "for para in paras:\n",
    "    print(para.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf148654",
   "metadata": {},
   "source": [
    "After that, you can split the string and get the article!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_string = [para.get_text().strip() for para in paras]\n",
    "final_string = \"\\n\".join(content_string)\n",
    "\n",
    "print(final_string)\n",
    "\n",
    "# write into file\n",
    "\n",
    "with open(\"demo.md\", \"w\") as file:\n",
    "    file.write(final_string)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd435da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = soup_lilian.find_all(\"a\")\n",
    "for ref in refs:\n",
    "    print(ref.attrs[\"href\"])\n",
    "    # attrs is a dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
